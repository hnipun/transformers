CONFIGS = dict(
    batch_size=64,
    seq_length=128,
    embedding_dim=16,
    num_embeddings=65,  # vocab size of the data not a hyper_parameter
    n_transformer_layers=3
)
